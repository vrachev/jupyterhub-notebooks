{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b2184f",
   "metadata": {},
   "source": [
    "Currently Release Management uses a sys-perf comparison on the Performance Discovery plugin as: <br><br>\n",
    "\n",
    "<center>$ 50 \\% \\lt \\left ( 100 \\times {\\LARGE \\frac{y_{rc}}{y_{ga}}} \\right )  \\lt 150 \\% $ </center>\n",
    "\n",
    "where $ \\large y_{rc}$ is the measurement of the new release candidate, and $ \\large y_{ga}$ is the measurement of the last point release.\n",
    "\n",
    "The proposal is to use the new variables: <br>\n",
    "<center> <b>percent</b> = $  100 \\times \\LARGE \\left ( \\frac{y_{rc} - \\bar{y}}{\\bar{y}} \\right ) $ </center>\n",
    "<br>\n",
    "<center><b>z_score</b> = $ \\LARGE \\frac{y_{rc} - \\bar{y}}{\\sigma_y} $ </center>\n",
    "\n",
    "where $\\large \\bar{y} $ and $ \\large \\sigma_y $ refer to the mean and standard deviation since the last <b>Change Point</b>.\n",
    "\n",
    "Advantages:\n",
    "- more accurate as it uses more of the time series data\n",
    "- can tighten the current filter from $\\pm 50 \\%$\n",
    "- reduces signal to noise\n",
    "- Use different limits for iop/s and latency\n",
    "\n",
    "Disadvantages:\n",
    "- takes more time to run the analysis: \n",
    "    -  4 minutes to load all the 4.4.7/4.4.8 tasks over REST\n",
    "    -  6 minutes to run the mean/standard deviation algorithm on the analytics database (3,000 charts)\n",
    "- Not all the legacy data is available (started over a year ago, but some tests have been broken)\n",
    "    \n",
    "To Do:\n",
    "- Pick the limits - run on different branches over the next few releases\n",
    "    - abs(percent) > 25% | abs(z_score) > 2\n",
    "- Understand the new metrics\n",
    "    - system cpu user (%) - mean\n",
    "    - ss mem resident (MiB) - mean\n",
    "    - Data - disk xvde utilization (%) - mean\n",
    "    - Journal - disk xvdf utilization (%) - mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5541b986-ef8d-4883-9837-ef351c4558ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vrachev/github/jupyterhub-notebooks/venv/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from more_itertools import pairwise\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "from jupyter_datatables import init_datatables_mode\n",
    "\n",
    "from nblib import data, perfdisclib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e502f7c8-a16d-4504-997c-d91cd7a86361",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_a = \"sys_perf_4.4_abb6b9c2bf675e9e2aeaecba05f0f8359d99e203\" \n",
    "build_a_label = '4.4.7'\n",
    "build_b = \"sys_perf_4.4_83b8bb8b6b325d8d8d3dfd2ad9f744bdad7d6ca0\"\n",
    "build_b_label = '4.4.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0406bca-8d62-43db-9e59-ca735ee2e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_disc_info = perfdisclib.Info(max_tasks=4000, max_tests=20000, batch=100, build_a=build_a, build_a_label=build_a_label, build_b=build_b, build_b_label=build_b_label)\n",
    "perf_disc_analysis = perfdisclib.Analysis(perf_disc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021c4c82-b9e4-4910-a344-c6570848bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = data.PerfAtlasClient().conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4abf20c-5b19-4064-b942-a3a5878ebf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tasks for sys_perf_4.4_abb6b9c2bf675e9e2aeaecba05f0f8359d99e203\n",
      "Tasks fetched: 4000\n",
      "Finished fetching tasks\n",
      "Fetching tasks for sys_perf_4.4_83b8bb8b6b325d8d8d3dfd2ad9f744bdad7d6ca0\n",
      "Tasks fetched: 4000\n",
      "Finished fetching tasks\n",
      "CPU times: user 2.16 s, sys: 414 ms, total: 2.57 s\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get the list of tasks from the 2 commits.\n",
    "\n",
    "dfa = perf_disc_analysis.read_task_list(perf_disc_analysis.pd_info.build_a)\n",
    "dfb = perf_disc_analysis.read_task_list(perf_disc_analysis.pd_info.build_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17997157-1012-4d6a-9e2c-13b12a713c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_filters = [re.compile(\"^(canary_|fio_|iperf|NetworkBandwidth|[01]_1c_avg_latency|[01]_1c_max_latency|oplog1|finishing|CleanUp|\"\n",
    "#     \"Setup|Quiesce|GennyOverhead|ShardCollection|EnableSharding|genny_canaries|nop_)\"),\n",
    "#     re.compile(\"Setup|ActorFinished|ActorStarted\")]\n",
    "\n",
    "task_filers = [re.compile(\"^(CleanUp|canary|fio|iperf|NetworkBandwidth|finishing|Setup|Quiesce|GennyOverhead)\"), re.compile('ActorFinished|ActorStarted|Setup')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14dc0e72-99a5-41a5-9126-a99207e881a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 16:53:36,274 [72547] WARNING  py.warnings:109: [JupyterRequire] /Users/vrachev/github/jupyterhub-notebooks/nblib/perfdisclib.py:77: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  print(df_filtered.test.str.contains(task_filter))\n",
      "\n",
      "2021-12-01 16:53:36,305 [72547] WARNING  py.warnings:109: [JupyterRequire] /Users/vrachev/github/jupyterhub-notebooks/nblib/perfdisclib.py:78: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df_filtered = df_filtered[~df_filtered.test.str.contains(task_filter)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfa length = 35323, dfb length = 38354\n",
      "20       False\n",
      "21       False\n",
      "22       False\n",
      "23       False\n",
      "24       False\n",
      "         ...  \n",
      "40854    False\n",
      "40855    False\n",
      "40856    False\n",
      "40857    False\n",
      "40858    False\n",
      "Name: test, Length: 35323, dtype: bool\n",
      "20       False\n",
      "21       False\n",
      "22       False\n",
      "23       False\n",
      "24       False\n",
      "         ...  \n",
      "40854    False\n",
      "40855    False\n",
      "40856    False\n",
      "40857    False\n",
      "40858    False\n",
      "Name: test, Length: 35139, dtype: bool\n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "44265    False\n",
      "44266    False\n",
      "44267    False\n",
      "44268    False\n",
      "44269    False\n",
      "Name: test, Length: 38354, dtype: bool\n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "44265    False\n",
      "44266    False\n",
      "44267    False\n",
      "44268    False\n",
      "44269    False\n",
      "Name: test, Length: 38220, dtype: bool\n",
      "filtered dfa length = 35139, filtered dfb length = 38220\n",
      "length of merged comparison = 24543\n",
      "length after de-dup = 22500\n",
      "length after keeping interesting metrics = 1746\n",
      "CPU times: user 281 ms, sys: 17.9 ms, total: 299 ms\n",
      "Wall time: 296 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dfa1, dfb1 = perf_disc_analysis.filter_and_merge(dfa, dfb, task_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfa length =  40859  dfb length =  44270\n",
      "filtered  35323   38354\n",
      "length of merged comparison =  24719\n",
      "length after de-dup =  22550\n",
      "length after keeping interesting metrics =  1756\n",
      "CPU times: user 336 ms, sys: 19.6 ms, total: 355 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Filter and merge the tasks from the 2 commits\n",
    "\n",
    "def filter_canaries(dframe):\n",
    "\n",
    "    dframe_filtered = dframe[~dframe.test.str.match('CleanUp|canary|fio|iperf|NetworkBandwidth|finishing|Setup|Quiesce|GennyOverhead')]\n",
    "    dframe_filtered = dframe_filtered[~dframe_filtered.test.str.contains('ActorFinished|ActorStarted|Setup')]\n",
    "    return dframe_filtered\n",
    "\n",
    "print('dfa length = ', len(dfa),' dfb length = ', len(dfb))\n",
    "\n",
    "dfa = filter_canaries(dfa)\n",
    "dfb = filter_canaries(dfb)\n",
    "\n",
    "print('filtered ', len(dfa),' ', len(dfb))\n",
    "\n",
    "dfa[\"args\"]= dfa[\"args\"].apply(json.dumps)\n",
    "dfb[\"args\"]= dfb[\"args\"].apply(json.dumps)\n",
    "\n",
    "# merge our results together:\n",
    "comparison = dfa.merge(dfb, on=[\"project\",\"variant\",\"task\",\"test\",\"measurement\",\"args\"])\n",
    "\n",
    "print('length of merged comparison = ', len(comparison))\n",
    "\n",
    "found_ts = comparison[[\"project\",\"variant\",\"task\",\"test\",\"measurement\",\"args\"]]\n",
    "\n",
    "# We drop duplicates since there could be multiple executions for the same combination of the properties below.\n",
    "found_ts = found_ts.drop_duplicates()\n",
    "\n",
    "print('length after de-dup = ', len(found_ts))\n",
    "\n",
    "# keep the interesting metrics\n",
    "found_ts = found_ts[found_ts[\"measurement\"].isin(['AverageLatency',\n",
    "                                                  'ops_per_sec',\n",
    "                                                  'system cpu user (%) - mean',\n",
    "                                                  'ss mem resident (MiB) - mean',\n",
    "                                                  'Data - disk xvde utilization (%) - mean',\n",
    "                                                  'Journal - disk xvdf utilization (%) - mean'])]\n",
    "\n",
    "print('length after keeping interesting metrics = ', len(found_ts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e1e72c-f560-4f67-98e6-735a9d0dcb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>variant</th>\n",
       "      <th>task</th>\n",
       "      <th>test</th>\n",
       "      <th>measurement</th>\n",
       "      <th>args</th>\n",
       "      <th>execution</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-shard-lite</td>\n",
       "      <td>bestbuy_query</td>\n",
       "      <td>find_project_6_sort_unindexed_skip_limit_1-noAgg</td>\n",
       "      <td>ops_per_sec</td>\n",
       "      <td>{\"thread_level\": 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.954792e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-shard-lite</td>\n",
       "      <td>bestbuy_query</td>\n",
       "      <td>find_project_6_sort_indexed_skip_limit_1-noAgg</td>\n",
       "      <td>ops_per_sec</td>\n",
       "      <td>{\"thread_level\": 32}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.572742e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-shard-lite</td>\n",
       "      <td>bestbuy_query</td>\n",
       "      <td>find_project_6_sort_indexed_skip_limit_1-noAgg</td>\n",
       "      <td>ops_per_sec</td>\n",
       "      <td>{\"thread_level\": 16}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.578922e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-shard-lite</td>\n",
       "      <td>bestbuy_query</td>\n",
       "      <td>find_project_6_sort_indexed_skip_limit_1-noAgg</td>\n",
       "      <td>ops_per_sec</td>\n",
       "      <td>{\"thread_level\": 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>2.746334e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-shard-lite</td>\n",
       "      <td>bestbuy_query</td>\n",
       "      <td>find_project_skip_limit-noAgg</td>\n",
       "      <td>ops_per_sec</td>\n",
       "      <td>{\"thread_level\": 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.774970e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40371</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-standalone</td>\n",
       "      <td>union_with</td>\n",
       "      <td>AddCollections.DatabaseOperation.1.1</td>\n",
       "      <td>ErrorsTotal</td>\n",
       "      <td>\"null\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40372</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-standalone</td>\n",
       "      <td>union_with</td>\n",
       "      <td>AddCollections.DatabaseOperation.1.1</td>\n",
       "      <td>OperationsTotal</td>\n",
       "      <td>\"null\"</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40373</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-standalone</td>\n",
       "      <td>union_with</td>\n",
       "      <td>AddCollections.DatabaseOperation.1.1</td>\n",
       "      <td>DocumentsTotal</td>\n",
       "      <td>\"null\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40374</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-standalone</td>\n",
       "      <td>union_with</td>\n",
       "      <td>AddCollections.DatabaseOperation.1.1</td>\n",
       "      <td>SizeTotal</td>\n",
       "      <td>\"null\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40375</th>\n",
       "      <td>sys-perf-4.4</td>\n",
       "      <td>linux-standalone</td>\n",
       "      <td>union_with</td>\n",
       "      <td>AddCollections.DatabaseOperation.1.1</td>\n",
       "      <td>OverheadTotal</td>\n",
       "      <td>\"null\"</td>\n",
       "      <td>0</td>\n",
       "      <td>3.623224e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56770 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            project           variant           task  \\\n",
       "20     sys-perf-4.4  linux-shard-lite  bestbuy_query   \n",
       "21     sys-perf-4.4  linux-shard-lite  bestbuy_query   \n",
       "22     sys-perf-4.4  linux-shard-lite  bestbuy_query   \n",
       "23     sys-perf-4.4  linux-shard-lite  bestbuy_query   \n",
       "24     sys-perf-4.4  linux-shard-lite  bestbuy_query   \n",
       "...             ...               ...            ...   \n",
       "40371  sys-perf-4.4  linux-standalone     union_with   \n",
       "40372  sys-perf-4.4  linux-standalone     union_with   \n",
       "40373  sys-perf-4.4  linux-standalone     union_with   \n",
       "40374  sys-perf-4.4  linux-standalone     union_with   \n",
       "40375  sys-perf-4.4  linux-standalone     union_with   \n",
       "\n",
       "                                                   test      measurement  \\\n",
       "20     find_project_6_sort_unindexed_skip_limit_1-noAgg      ops_per_sec   \n",
       "21       find_project_6_sort_indexed_skip_limit_1-noAgg      ops_per_sec   \n",
       "22       find_project_6_sort_indexed_skip_limit_1-noAgg      ops_per_sec   \n",
       "23       find_project_6_sort_indexed_skip_limit_1-noAgg      ops_per_sec   \n",
       "24                        find_project_skip_limit-noAgg      ops_per_sec   \n",
       "...                                                 ...              ...   \n",
       "40371              AddCollections.DatabaseOperation.1.1      ErrorsTotal   \n",
       "40372              AddCollections.DatabaseOperation.1.1  OperationsTotal   \n",
       "40373              AddCollections.DatabaseOperation.1.1   DocumentsTotal   \n",
       "40374              AddCollections.DatabaseOperation.1.1        SizeTotal   \n",
       "40375              AddCollections.DatabaseOperation.1.1    OverheadTotal   \n",
       "\n",
       "                       args  execution         value  \n",
       "20      {\"thread_level\": 1}          1  2.954792e-01  \n",
       "21     {\"thread_level\": 32}          1  2.572742e+03  \n",
       "22     {\"thread_level\": 16}          1  2.578922e+03  \n",
       "23      {\"thread_level\": 1}          1  2.746334e+02  \n",
       "24      {\"thread_level\": 1}          1  1.774970e+01  \n",
       "...                     ...        ...           ...  \n",
       "40371                \"null\"          0  0.000000e+00  \n",
       "40372                \"null\"          0  5.000000e+00  \n",
       "40373                \"null\"          0  0.000000e+00  \n",
       "40374                \"null\"          0  0.000000e+00  \n",
       "40375                \"null\"          0  3.623224e+09  \n",
       "\n",
       "[56770 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dfa,dfa1]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f759c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Alex Costas: Algorithm to look up time series from the anaytics node in able to characterize \n",
    "# the stable region of results around build_a.\n",
    "\n",
    "def get_stable_region(commit_date, ts, cps):\n",
    "       \n",
    "    true_positive_orders = {\n",
    "        cp[\"order\"]\n",
    "        for cp in cps\n",
    "        if cp[\"triage\"][\"triage_status\"] == \"true_positive\"\n",
    "    }\n",
    "    len_ts = len(ts[\"data\"])\n",
    "    stable_region_bounds = (\n",
    "        [0]\n",
    "        + [idx for idx, datum in enumerate(ts[\"data\"]) if datum[\"order\"] in true_positive_orders]\n",
    "        + [len_ts]\n",
    "    )\n",
    "\n",
    "    start = end = 0\n",
    "\n",
    "    # if base commit before or after the entire time series, get the closest stable region\n",
    "    if commit_date < ts[\"data\"][0][\"commit_date\"]:\n",
    "        # first stable region\n",
    "        start = stable_region_bounds[0]\n",
    "        end = stable_region_bounds[1]\n",
    "\n",
    "    if commit_date > ts[\"data\"][len_ts - 1][\"commit_date\"]:\n",
    "        # last stable region\n",
    "        start = stable_region_bounds[-2]\n",
    "        end = stable_region_bounds[-1]\n",
    "\n",
    "    for start_bound, end_bound in pairwise(stable_region_bounds):\n",
    "        if (\n",
    "            ts[\"data\"][start_bound][\"commit_date\"]\n",
    "            <= commit_date\n",
    "            <= ts[\"data\"][end_bound - 1][\"commit_date\"]\n",
    "        ):\n",
    "            start = start_bound\n",
    "            end = end_bound\n",
    "    return [datum[\"value\"] for datum in ts[\"data\"][start:end]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Calculate the means and std dev for the Zscores\n",
    "# Must be on VPN to read the analytics DB\n",
    "print('')\n",
    "# limit number of tests\n",
    "found_ts = found_ts[0:max_tests]\n",
    "\n",
    "total = len(found_ts)\n",
    "\n",
    "stable_mean = []\n",
    "stable_std = []\n",
    "stable_length = []\n",
    "\n",
    "date_a = client[\"expanded_metrics\"][\"versions\"].find_one({\"version_id\": build_a})[\"commit_date\"]\n",
    "date_b = client[\"expanded_metrics\"][\"versions\"].find_one({\"version_id\": build_b})[\"commit_date\"]\n",
    "\n",
    "for index, row in found_ts.iterrows():\n",
    "    # some tests do not have threads.\n",
    "    if row[\"args\"] == \"null\":\n",
    "            row[\"args\"] = \"{}\"\n",
    "    ts = client[\"expanded_metrics\"][\"time_series\"].find_one({\n",
    "            \"project\": row[\"project\"],\n",
    "            \"variant\": row[\"variant\"],\n",
    "            \"task\": row[\"task\"],\n",
    "            \"test\": row[\"test\"],\n",
    "            \"args\": json.loads(row[\"args\"]),\n",
    "            \"measurement\": row[\"measurement\"],\n",
    "        })\n",
    "    cps = list(client[\"expanded_metrics\"][\"change_points\"].find({\n",
    "            \"time_series_info.project\": row[\"project\"],\n",
    "            \"time_series_info.variant\": row[\"variant\"],\n",
    "            \"time_series_info.task\": row[\"task\"],\n",
    "            \"time_series_info.test\": row[\"test\"],\n",
    "            \"time_series_info.args\": json.loads(row[\"args\"]),\n",
    "            \"time_series_info.measurement\": row[\"measurement\"],\n",
    "    }))\n",
    "    \n",
    "    try:\n",
    "      stable_region = get_stable_region(date_a, ts, cps)\n",
    "      stable_mean.append(np.mean(stable_region))\n",
    "      stable_std.append(np.std(stable_region))\n",
    "      stable_length.append(len(stable_region))\n",
    "    except:\n",
    "        # no stable region found\n",
    "        print('')\n",
    "        print('no stable region found for ', len(stable_length))\n",
    "        print('')\n",
    "        stable_mean.append(np.nan)\n",
    "        stable_std.append(np.nan)\n",
    "        stable_length.append(0)\n",
    "        pass\n",
    "    \n",
    "    print('{}/{}'.format(len(stable_length), total), end='\\r')\n",
    "\n",
    "print('')\n",
    "found_ts.insert(0, \"stable_mean\", stable_mean)\n",
    "found_ts.insert(1, \"stable_std\", stable_std)\n",
    "found_ts.insert(2, \"stable_length\", stable_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the results together:\n",
    "comparison = comparison.merge(found_ts, on=[\"project\",\"variant\",\"task\",\"test\",\"measurement\",\"args\"])\n",
    "\n",
    "#comparison[\"difference\"] = comparison[\"value_y\"] - comparison[\"value_x\"]\n",
    "#comparison[\"percentage_change\"] = ((comparison[\"value_y\"] / comparison[\"value_x\"]) * 100) - 100\n",
    "#comparison[\"difference_from_stable_mean\"] = comparison[\"value_y\"] - comparison[\"stable_mean\"]\n",
    "comparison[\"percent\"] = ((comparison[\"value_y\"] / (1.E-3+comparison[\"stable_mean\"])) * 100) - 100\n",
    "comparison[\"z_score\"] = (comparison[\"value_y\"] - comparison[\"stable_mean\"]) / (1.E-3+comparison[\"stable_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to CSV\n",
    "with open(\"compare.csv\", \"w\") as csv:\n",
    "    comparison.to_csv(csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram the Zscores\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14,14)\n",
    "\n",
    "comparison[\"z_score\"].hist(by=comparison[\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram the % changes\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14,14)\n",
    "\n",
    "comparison[\"percent\"].hist(by=comparison[\"measurement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb125d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plots \n",
    "\n",
    "# %matplotlib widget\n",
    "# %matplotlib ipympl\n",
    "\n",
    "# %matplotlib inline\n",
    "# loses Engineering format\n",
    "# import mpld3\n",
    "# mpld3.enable_notebook()\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (12, 8),\n",
    "         'axes.labelsize': 16,\n",
    "         'axes.titlesize': 16,\n",
    "         'xtick.labelsize':14,\n",
    "         'ytick.labelsize':14\n",
    "         }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "fig, axs = plt.subplots(3,2, figsize=(12,12))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.5)\n",
    "\n",
    "axs = axs.ravel()\n",
    "i=0\n",
    "for t in ['AverageLatency',\n",
    "'ops_per_sec',\n",
    "'system cpu user (%) - mean',\n",
    "'ss mem resident (MiB) - mean',\n",
    "'Data - disk xvde utilization (%) - mean',\n",
    "'Journal - disk xvdf utilization (%) - mean']:\n",
    "    axs[i].yaxis.set_major_formatter(EngFormatter()) \n",
    "    axs[i].set_title(t)\n",
    "    axs[i].set(xlabel=\"percent\", ylabel=\"z_score\")\n",
    "    axs[i].scatter(comparison[\"percent\"][(comparison[\"measurement\"] == t)],\n",
    "             comparison[\"z_score\"][(comparison[\"measurement\"] == t)], s=5)\n",
    "    i=i+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(row_num):\n",
    "    \n",
    "    # put chart on a new pop-up    \n",
    "    from IPython import get_ipython\n",
    "    # %matplotlib widget\n",
    "    %matplotlib qt\n",
    "\n",
    "    project = comparison.loc[row_num, 'project']\n",
    "    variant = comparison.loc[row_num, 'variant']\n",
    "    task = comparison.loc[row_num, 'task']\n",
    "    test = comparison.loc[row_num, 'test']\n",
    "    measurement = comparison.loc[row_num, 'measurement']    \n",
    "    args = comparison.loc[row_num, 'args']\n",
    "    value_x = comparison.loc[row_num, 'value_x']\n",
    "    value_y = comparison.loc[row_num, 'value_y']\n",
    "    z_score = comparison.loc[row_num, 'z_score']\n",
    "    percent = comparison.loc[row_num, 'percent']\n",
    "    stable_mean = comparison.loc[row_num, 'stable_mean']\n",
    "    stable_std = comparison.loc[row_num, 'stable_std']\n",
    "\n",
    "    time_series = client[\"expanded_metrics\"][\"time_series\"].find_one(\n",
    "        { \"project\": project,\n",
    "          \"variant\": variant, \n",
    "          \"test\": test, \n",
    "          \"task\": task, \n",
    "          \"measurement\": measurement,\n",
    "         \"args\": json.loads(args)\n",
    "        }\n",
    "    )\n",
    "        \n",
    "    dates = [time_series_point[\"commit_date\"] for time_series_point in time_series[\"data\"]]\n",
    "    values = [time_series_point[\"value\"] for time_series_point in time_series[\"data\"]]\n",
    "\n",
    "    params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (16, 6),\n",
    "         'axes.labelsize': 24,\n",
    "         'axes.titlesize': 24,\n",
    "         'xtick.labelsize':10,\n",
    "         'ytick.labelsize':18}\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "    plt.suptitle(variant+' '+task+' '+test, fontsize=16)\n",
    "    plt.title(\"z_score = {:.2f}\".format(z_score)+\"  percent = {:.2f}\".format(percent), fontsize=10, loc='left')\n",
    "    plt.plot(dates, values)\n",
    "    \n",
    "    plt.xlabel(\"Commit Date\")\n",
    "    plt.ylabel(time_series[\"measurement\"])\n",
    "    \n",
    "    # add marks for the commits\n",
    "    plt.axvline(date_a, color=\"green\", linestyle=\"dotted\")\n",
    "    plt.text(date_a, value_x, build_a_label, rotation=90, fontsize=20)\n",
    "    plt.axhline(value_x, color=\"green\", linestyle=\"dotted\" )\n",
    "    plt.axvline(date_b, color=\"red\", linestyle=\"dashed\")\n",
    "    plt.text(date_b, value_y, build_b_label, rotation=90, fontsize=20)\n",
    "    plt.axhline(value_y, color=\"red\", linestyle=\"dashed\" )\n",
    "    plt.axhline(stable_mean, color=\"purple\", linestyle=\"dashdot\" )\n",
    "    plt.axhspan(stable_mean-stable_std, stable_mean+stable_std, facecolor=\"purple\", alpha=0.05)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76dddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the table as a qgrid\n",
    "\n",
    "# increase size of output window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 48em; }</style>\"))\n",
    "\n",
    "comparison = comparison.sort_values(by=['z_score', 'percent'], ignore_index=True)\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth', 20)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# qgrid floating format\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# add filter here to remove ok looking z_score & percentage differences\n",
    "\n",
    "ddf = df[[ 'variant', 'task', 'test', 'measurement',  'z_score', 'percent', \n",
    "          'value_x', 'value_y', 'stable_mean', 'stable_length', 'stable_std', 'args']]\n",
    "\n",
    "# save to disk\n",
    "with open(f\"selected_tasks_{build_a_label}_{build_b_label}.csv\", \"w\") as csv:\n",
    "    ddf.to_csv(csv)\n",
    "    \n",
    "import ipydatagrid\n",
    "\n",
    "info_grid = ipydatagrid.DataGrid(ddf)\n",
    "\n",
    "# display plot when row is selected\n",
    "def on_row_selected(change):    \n",
    "    plot_timeseries(change.new[0])\n",
    "    \n",
    "info_grid.observe(on_row_selected, names=['_selected_rows'])\n",
    "\n",
    "print('Click on a row to see the time-series')\n",
    "info_grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "require": {
   "paths": {
    "buttons.colvis": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.colVis.min",
    "buttons.flash": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.flash.min",
    "buttons.html5": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.html5.min",
    "buttons.print": "https://cdn.datatables.net/buttons/1.5.6/js/buttons.print.min",
    "chartjs": "https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart",
    "d3": "https://d3js.org/d3.v5.min",
    "d3-array": "https://d3js.org/d3-array.v2.min",
    "datatables.net": "https://cdn.datatables.net/1.10.18/js/jquery.dataTables",
    "datatables.net-buttons": "https://cdn.datatables.net/buttons/1.5.6/js/dataTables.buttons.min",
    "datatables.responsive": "https://cdn.datatables.net/responsive/2.2.2/js/dataTables.responsive.min",
    "datatables.scroller": "https://cdn.datatables.net/scroller/2.0.0/js/dataTables.scroller.min",
    "datatables.select": "https://cdn.datatables.net/select/1.3.0/js/dataTables.select.min",
    "jszip": "https://cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min",
    "moment": "https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.8.0/moment",
    "pdfmake": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/pdfmake.min",
    "vfsfonts": "https://cdnjs.cloudflare.com/ajax/libs/pdfmake/0.1.36/vfs_fonts"
   },
   "shim": {
    "buttons.colvis": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.flash": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.html5": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "buttons.print": {
     "deps": [
      "jszip",
      "datatables.net-buttons"
     ]
    },
    "chartjs": {
     "deps": [
      "moment"
     ]
    },
    "datatables.net": {
     "exports": "$.fn.dataTable"
    },
    "datatables.net-buttons": {
     "deps": [
      "datatables.net"
     ]
    },
    "pdfmake": {
     "deps": [
      "datatables.net"
     ]
    },
    "vfsfonts": {
     "deps": [
      "datatables.net"
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
